{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Prez context signal analysis\n",
        "subtitle: Taking a look at newly collected CST data\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-location: left\n",
        "    code-fold: true\n",
        "    execute: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Why we needed more data\n",
        "\n",
        "Our previous neural data from CO and CST with Earl and Ford suggested something that looked like at least one dimension of neural activity that specified the upcoming trial type (CO or CST), despite behavior being roughly similar in the center hold period across trial types. Because the monkeys knew which type of trial was coming up, this theoretically would allow them to prepare their behavior before movement in whatever way they needed to optimize their success.\n",
        "\n",
        "Unfortunately, those data had a few problems for this kind of analysis:\n",
        "\n",
        "1. Monkeys knew what kind of trial was coming up as they were reaching to the center target. This makes it difficult to study the evolution of this contextual preparation signal because it's confounded with a reach.\n",
        "2. CO was a much shorter task than CST, so it was possible that the signal we saw was merely anticipation of a quicker reward, rather than contextual preparation.\n",
        "3. CO behavior was much simpler ahead of the reward--only one moment of visual input necessary to specify the behavior for the entire trial in CO, unlike CST, where the monkey has to pay attention to the cursor throughout the trial.\n",
        "4. The split between CO and CST was not quite even during the main part of the recording session, so there may have been some bias in the monkeys' expectations of upcoming trial.\n",
        "5. CO involved movements in both horizontal and vertical axes, whereas CST involved movements in only the horizontal axis.\n",
        "\n",
        "For this reason, we collected new data from another monkey, this time with a few modifications:\n",
        "\n",
        "1. Instead of CO, we introduced the monkey to a new horizontal random target task (RTT). In the RTT, monkeys would reach to a visually presented target. Once the monkey reached the target, a new reach target would appear for the monkey to reach to. This would continue until the monkey reached to 8 targets sequentially, at which point the trial would end with a reward. Importantly, each of the 8 targets would be selected uniformly from a set of 17 targets lined up on the horizontal axis, so movements would only be horizontal. For this tasks, 8 targets seemed to be a good number to match the 6 second trial time of CST.\n",
        "2. At the start of the trial, monkeys would be presented with an ambiguous center target to reach and hold in, without knowing which type of trial was coming up. After a short delay (0.3-0.5s), the hold target would change shape to indicate which of the two tasks (CST or RTT) was coming up. After another short delay (0.5-0.75s), the trial would start.\n",
        "\n",
        "Ideally, these changes would allow for a more careful examination of the putative contextual preparation signal--this notebook serves as an investigation of that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import src\n",
        "import pyaldata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import k3d\n",
        "import yaml\n",
        "from sklearn.decomposition import PCA\n",
        "from ipywidgets import interact\n",
        "\n",
        "with open('../params.yaml','r') as f:\n",
        "    params = yaml.safe_load(f)\n",
        "    inspection_params = params['inspection']\n",
        "\n",
        "sns.set_context('talk')\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data inspection\n",
        "\n",
        "To start, let's import a dataset (2022/07/20) and preprocess it. This takes a number of preprocessing steps, and they should be fairly self-evident in the pipeline below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "td = (\n",
        "    pyaldata.mat2dataframe('../data/trial_data/Prez_20220720_RTTCSTCO_TD.mat', shift_idx_fields=True, td_name='trial_data')\n",
        "    .assign(\n",
        "        date_time=lambda x: pd.to_datetime(x['date_time']),\n",
        "        session_date=lambda x: pd.DatetimeIndex(x['date_time']).normalize()\n",
        "    )\n",
        "    .query('task==\"RTT\" | task==\"CST\"')\n",
        "    .pipe(src.data.remove_aborts, verbose=inspection_params['verbose'])\n",
        "    .pipe(src.data.remove_artifact_trials, verbose=inspection_params['verbose'])\n",
        "    .pipe(src.data.filter_unit_guides, filter_func=lambda guide: guide[:,1] > (0 if inspection_params['keep_unsorted'] else 1))\n",
        "    .pipe(src.data.remove_correlated_units)\n",
        "    .pipe(pyaldata.remove_low_firing_neurons, 'M1_spikes', threshold=0.1, divide_by_bin_size=True, verbose=inspection_params['verbose'])\n",
        "    .pipe(pyaldata.remove_low_firing_neurons, 'PMd_spikes', threshold=0.1, divide_by_bin_size=True, verbose=inspection_params['verbose'])\n",
        "    .pipe(pyaldata.remove_low_firing_neurons, 'MC_spikes', threshold=0.1, divide_by_bin_size=True, verbose=inspection_params['verbose'])\n",
        "    .pipe(pyaldata.add_firing_rates,method='smooth', std=0.05, backend='convolve')\n",
        "    .pipe(src.data.trim_nans, ref_signals=['rel_hand_pos'])\n",
        "    .pipe(src.data.fill_kinematic_signals)\n",
        "    .pipe(src.data.rebin_data,new_bin_size=inspection_params['bin_size'])\n",
        "    .pipe(pyaldata.soft_normalize_signal,signals=['M1_rates','PMd_rates','MC_rates'])\n",
        "    .pipe(pyaldata.dim_reduce,PCA(n_components=3),'M1_rates','M1_pca')\n",
        "    .pipe(pyaldata.dim_reduce,PCA(n_components=3),'PMd_rates','PMd_pca')\n",
        "    .pipe(pyaldata.dim_reduce,PCA(n_components=3),'MC_rates','MC_pca')\n",
        "    .assign(\n",
        "        **{\n",
        "            'idx_ctHoldTime': lambda x: x['idx_ctHoldTime'].map(lambda y: y[-1] if y.size>1 else y),\n",
        "            'Ambiguous Hold Period': lambda x: x['bin_size']*(x['idx_pretaskHoldTime'] - x['idx_ctHoldTime']),\n",
        "            'Cued Hold Period': lambda x: x['bin_size']*(x['idx_goCueTime'] - x['idx_pretaskHoldTime']),\n",
        "            'Movement Period': lambda x: x['bin_size']*(x['idx_endTime'] - x['idx_goCueTime']),\n",
        "        }\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Individual trials\n",
        "\n",
        "As a sanity check, let's check out the rasters from a couple random CST trials and RTT trials:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "_,axs = plt.subplots(4,1,figsize=(10,15),sharex=True)\n",
        "for ax,trial_id in zip(axs.flatten(),td.groupby('task').sample(n=2)['trial_id']):\n",
        "    trial = td.loc[td['trial_id']==trial_id,:].squeeze()\n",
        "    src.plot.make_trial_raster(\n",
        "        trial,\n",
        "        ax,\n",
        "        sig='MC_spikes',\n",
        "        events=[\n",
        "            'idx_ctHoldTime',\n",
        "            'idx_pretaskHoldTime',\n",
        "            'idx_goCueTime',\n",
        "            'idx_cstEndTime',\n",
        "            'idx_rtHoldTimes',\n",
        "        ],\n",
        "        ref_event_idx=trial['idx_goCueTime'])\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel(trial['task'])\n",
        "axs[0].set_title('Neuron Rasters')\n",
        "axs[-1].set_xlabel('Time (s)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's double-check the timing of each trial, just to make sure the task is happening the way we think it is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "g = sns.pairplot(\n",
        "    data=td.query('task==\"CST\" | task==\"RTT\"'),\n",
        "    vars=['Ambiguous Hold Period','Cued Hold Period','Movement Period'],\n",
        "    hue='task',\n",
        "    diag_kind='hist',\n",
        "    corner=True,\n",
        "    height=3,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural state space in RTT and CST\n",
        "\n",
        "First, let's take a look at the individual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cst_trace_plot = k3d.plot(name='CST smoothed neural traces')\n",
        "max_abs_hand_vel = np.percentile(np.abs(np.row_stack(td.query('task==\"CST\"')['hand_vel'])[:,0]),95)\n",
        "# plot traces\n",
        "for _,trial in td.query('task==\"CST\"').sample(n=10).iterrows():\n",
        "    neural_trace = trial['M1_pca']\n",
        "    cst_trace_plot+=k3d.line(\n",
        "        neural_trace[:,0:3].astype(np.float32),\n",
        "        shader='mesh',\n",
        "        width=3e-3,\n",
        "        attribute=trial['hand_vel'][:,0],\n",
        "        color_map=k3d.paraview_color_maps.Erdc_divHi_purpleGreen,\n",
        "        color_range=[-max_abs_hand_vel,max_abs_hand_vel],\n",
        "    )\n",
        "\n",
        "cst_trace_plot.display()\n",
        "\n",
        "rtt_trace_plot = k3d.plot(name='RTT smoothed neural traces')\n",
        "for _,trial in td.query('task==\"RTT\"').sample(n=10).iterrows():\n",
        "    neural_trace = trial['M1_pca']\n",
        "    rtt_trace_plot+=k3d.line(\n",
        "        neural_trace[:,0:3].astype(np.float32),\n",
        "        shader='mesh',\n",
        "        width=3e-3,\n",
        "        attribute=trial['hand_vel'][:,0],\n",
        "        #attribute=150*np.ones(neural_trace.shape[0]),\n",
        "        color_map=k3d.paraview_color_maps.Erdc_divHi_purpleGreen,\n",
        "        color_range=[-max_abs_hand_vel,max_abs_hand_vel],\n",
        "    )\n",
        "rtt_trace_plot.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def extract_td_epochs(td):\n",
        "    '''\n",
        "    Prepare data for hold-time PCA and LDA, as well as data for smooth hold/move M1 activity\n",
        "    \n",
        "    Arguments:\n",
        "        args (Namespace): Namespace of command-line arguments\n",
        "        \n",
        "    Returns:\n",
        "        td_binned (DataFrame): PyalData formatted structure of neural/behavioral data\n",
        "        td_smooth (DataFrame): PyalData formatted structure of neural/behavioral data\n",
        "    '''\n",
        "    binned_epoch_dict = {\n",
        "        'ambig_hold': src.util.generate_realtime_epoch_fun(\n",
        "            'idx_pretaskHoldTime',\n",
        "            rel_start_time=-0.3,\n",
        "        ),\n",
        "        'hold': src.util.generate_realtime_epoch_fun(\n",
        "            'idx_goCueTime',\n",
        "            rel_start_time=-0.3,\n",
        "        ),\n",
        "        'move': src.util.generate_realtime_epoch_fun(\n",
        "            'idx_goCueTime',\n",
        "            rel_start_time=0,\n",
        "            rel_end_time=0.3,\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    td_binned = (\n",
        "        td.copy()\n",
        "        .pipe(src.util.split_trials_by_epoch,binned_epoch_dict)\n",
        "        .pipe(src.data.rebin_data,new_bin_size=0.3)\n",
        "        .pipe(pyaldata.add_firing_rates,method='bin')\n",
        "    )\n",
        "\n",
        "    spike_fields = [name for name in td.columns.values if name.endswith(\"_spikes\")]\n",
        "    for field in spike_fields:\n",
        "        assert td_binned[field].values[0].ndim==1, \"Binning didn't work\"\n",
        "\n",
        "    smooth_epoch_dict = {\n",
        "        'hold_move': src.util.generate_realtime_epoch_fun(\n",
        "            'idx_goCueTime',\n",
        "            rel_start_time=-0.8,\n",
        "            rel_end_time=0.5,\n",
        "        ),\n",
        "        'hold_move_ref_cue': src.util.generate_realtime_epoch_fun(\n",
        "            'idx_pretaskHoldTime',\n",
        "            rel_start_time=-0.3,\n",
        "            rel_end_time=1.0,\n",
        "        ),\n",
        "        'full': lambda trial : slice(0,trial['hand_pos'].shape[0]),\n",
        "    }\n",
        "    td_smooth = (\n",
        "        td.copy()\n",
        "        .pipe(pyaldata.add_firing_rates,method='smooth',std=0.05,backend='convolve')\n",
        "        .pipe(src.util.split_trials_by_epoch,smooth_epoch_dict)\n",
        "        .pipe(src.data.rebin_data,new_bin_size=0.05)\n",
        "    )\n",
        "\n",
        "    td_epochs = pd.concat([td_binned,td_smooth]).reset_index()\n",
        "\n",
        "    return td_epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "td_epoch = extract_td_epochs(td.rename(columns={'M1_rates':'M1_orig_rates','MC_rates':'M1_rates'}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "td_train,td_test = src.context_analysis.apply_models(td_epoch,train_epochs=['ambig_hold'],test_epochs=['hold_move','hold_move_ref_cue','full'])\n",
        "\n",
        "fig_gen_dict = {\n",
        "    'task_M1_pca':src.context_analysis.plot_hold_pca(td_train,array_name='M1',hue_order=['RTT','CST']),\n",
        "    'task_M1_lda':src.context_analysis.plot_M1_lda(td_train,hue_order=['RTT','CST']),\n",
        "    'task_beh':src.context_analysis.plot_hold_behavior(td_train,hue_order=['RTT','CST']),\n",
        "    'task_beh_lda':src.context_analysis.plot_beh_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_potent': src.plot_M1_hold_potent(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_potent_lda': src.plot_M1_potent_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_null_lda': src.plot_M1_null_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # LDA traces\n",
        "    'task_lda_trace':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"hold_move\"'),ref_event='idx_goCueTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "    'task_lda_trace_pretask':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"hold_move_ref_cue\"'),ref_event='idx_pretaskHoldTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "    'task_lda_trace':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"full\"'),ref_event='idx_goCueTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "td_train,td_test = src.context_analysis.apply_models(td_epoch,train_epochs=['hold'],test_epochs=['hold_move','hold_move_ref_cue','full'])\n",
        "\n",
        "fig_gen_dict = {\n",
        "    'task_M1_pca':src.context_analysis.plot_hold_pca(td_train,array_name='M1',hue_order=['RTT','CST']),\n",
        "    'task_M1_lda':src.context_analysis.plot_M1_lda(td_train,hue_order=['RTT','CST']),\n",
        "    'task_beh':src.context_analysis.plot_hold_behavior(td_train,hue_order=['RTT','CST']),\n",
        "    'task_beh_lda':src.context_analysis.plot_beh_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_potent': src.plot_M1_hold_potent(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_potent_lda': src.plot_M1_potent_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_null_lda': src.plot_M1_null_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # LDA traces\n",
        "    'task_lda_trace':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"hold_move\"'),ref_event='idx_goCueTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "    'task_lda_trace_pretask':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"hold_move_ref_cue\"'),ref_event='idx_pretaskHoldTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "    'task_lda_trace':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"full\"'),ref_event='idx_goCueTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "td_train,td_test = src.context_analysis.apply_models(td_epoch,train_epochs=['move'],test_epochs=['hold_move','hold_move_ref_cue','full'])\n",
        "\n",
        "fig_gen_dict = {\n",
        "    'task_M1_pca':src.context_analysis.plot_hold_pca(td_train,array_name='M1',hue_order=['RTT','CST']),\n",
        "    'task_M1_lda':src.context_analysis.plot_M1_lda(td_train,hue_order=['RTT','CST']),\n",
        "    'task_beh':src.context_analysis.plot_hold_behavior(td_train,hue_order=['RTT','CST']),\n",
        "    'task_beh_lda':src.context_analysis.plot_beh_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_potent': src.plot_M1_hold_potent(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_potent_lda': src.plot_M1_potent_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # 'task_M1_null_lda': src.plot_M1_null_lda(td_train,hue_order=['RTT','CST']),\n",
        "    # LDA traces\n",
        "    'task_lda_trace':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"hold_move\"'),ref_event='idx_goCueTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "    'task_lda_trace_pretask':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"hold_move_ref_cue\"'),ref_event='idx_pretaskHoldTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "    'task_lda_trace':src.context_analysis.plot_M1_lda_traces(td_test.query('epoch==\"full\"'),ref_event='idx_goCueTime',label_colors={'RTT':'r','CST':'b'}),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}