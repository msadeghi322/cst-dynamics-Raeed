---
title: Neural dynamics of CST and CO
subtitle: Investigation of neural tangling and LFADS inputs in CST and CO
format:
  html:
    toc: true
    toc-location: left
    cap-location: margin
    code-fold: true
    execute: true
    self-contained: true
jupyter: python3
---

# Investigation of neural tangling and LFADS inputs in CST and CO

In this notebook, I'm looking at a few things related to how input-driven the neural dynamics of different tasks are. In particular, I'm most interested in the timing of input processing in motor cortex as the monkey performs CO or CST.

In CO, the monkey holds in place and then gets a cue for which target to reach to. At this point, the neural trajectories should separate into the target-related trajectories. These trajectories look like autonomous dynamics, but at the point of separation, there has to be some input coming into motor cortex to signal which trajectory to start on--at this point, LFADS inputs should be high, and so should tangling. We know that the tangling result is true in the trial averages from the Russo 2018 paper, but it's been hard to see in single trials--which is where LFADS comes in. This is the first thing to check.

The next thing, assuming that bears out at the single trial level, is to examine the timecourse of neural tangling and LFADS inputs during CST. Hypothesis: we might get high tangling when the monkey changes his mind about what he should be doing, e.g. when he's holding still but then decides to move to counteract the cursor movement.

```{python}
import src
import pyaldata
import yaml
import numpy as np
import pandas as pd

from sklearn.decomposition import PCA

import seaborn as sns
import k3d
import matplotlib.pyplot as plt

sns.set_context('paper')

%load_ext autoreload
%autoreload 2
```

```{python}
with open('../params.yaml', 'r') as params_file:
    full_params = yaml.safe_load(params_file)
    lfads_params = full_params['lfads_prep']
    analysis_params = full_params['dynamics_analysis']

trial_data = (
    pyaldata.mat2dataframe('../data/trial_data/Earl_20190716_COCST_TD.mat', True, "trial_data")
    .assign(
        date_time=lambda x: pd.to_datetime(x['date_time']),
        session_date=lambda x: pd.DatetimeIndex(x['date_time']).normalize()
    )
    .pipe(src.data.remove_aborts, verbose=analysis_params['verbose'])
    .pipe(src.data.remove_artifact_trials, verbose=analysis_params['verbose'])
    .pipe(src.data.filter_unit_guides, filter_func=lambda guide: guide[:,1] > (0 if analysis_params['keep_unsorted'] else 1))
    .pipe(src.data.remove_correlated_units)
    .pipe(src.data.remove_all_low_firing_neurons, threshold=0.1, divide_by_bin_size=True, verbose=analysis_params['verbose'])
)

def task_spec_preproc_pipeline(td_task):
    return (
        td_task
        .pipe(pyaldata.add_firing_rates,method='smooth', std=0.05, backend='convolve')
        # Note: this runs soft normalization on each task individually instead of across tasks
        # TODO: fix this to make soft normalization across tasks (will have to deal with nans somehow)
        .pipe(pyaldata.soft_normalize_signal,signals=['M1_rates','lfads_rates'])
        .pipe(pyaldata.dim_reduce,PCA(n_components=analysis_params['num_dims']),'M1_rates','M1_pca')
        .pipe(pyaldata.dim_reduce,PCA(n_components=analysis_params['num_dims']),'lfads_rates','lfads_pca')
        .pipe(pyaldata.add_gradient,'lfads_pca',normalize=True)
        .pipe(pyaldata.add_gradient,'M1_pca',normalize=True)
    )

co_epoch_fun = src.util.generate_realtime_epoch_fun(
    'idx_goCueTime',
    rel_start_time=-1.0,
    rel_end_time=0.5,
)
cst_epoch_fun = src.util.generate_realtime_epoch_fun(
    'idx_goCueTime',
    rel_start_time=-1.0,
    rel_end_time=5.0,
)

td_co = (
    trial_data
    .pipe(src.lfads_helpers.prep_data_with_lfads, 'CO', lfads_params)
    .pipe(task_spec_preproc_pipeline)
    .pipe(pyaldata.restrict_to_interval,epoch_fun=co_epoch_fun)
    .pipe(src.data.rebin_data,new_bin_size=analysis_params['bin_size'])
)

td_cst = (
    trial_data
    .pipe(src.lfads_helpers.prep_data_with_lfads,'CST', lfads_params)
    .pipe(task_spec_preproc_pipeline)
    .pipe(pyaldata.restrict_to_interval,epoch_fun=cst_epoch_fun)
    .pipe(src.data.rebin_data,new_bin_size=analysis_params['bin_size'])
)
```

# What can LFADS do for us?

LFADS is a powerful tool, but it's important to make sure that the benefits outweigh the costs of running the models. Ideally, we'd like LFADS to reveal dynamical structure in the neural data that's difficult or impossible to see at the single trial level. To make sure that LFADS is actually doing what we want it to do, we'll need to run a few sanity checks. There are a few things we expect from a good dynamic model:

1. Neural trajectories should look like they have some more structure in them at the single trial level than previously--LFADS has previously shown single trial structure that has only been found at the trial average level, so that's what we expect. This check is more of a gut-check, since we don't really know what structure we're looking for, but it's something that we'll keep in mind throughout the analysis.
2. LFADS-smoothing should increase behavioral decoding performance. Because LFADS only has access to the neural data (and because of the chopping and merging, it doesn't even have access to trial timing), an improvement in behavioral decoding goes a long way towards showing that LFADS is actually revealing relevant structure in the neural data, rather than just smoothing it out arbitrarily.

## Smoother (more structured?) neural trajectories

First thing to do is to take a look at the neural trajectories in CST and CO trials, with and without LFADS. This will let us see whether LFADS appears to reveal any structure in the data that isn't there when we just look at smoothed neural activity.

Let's start with CO, comparing Gaussian-smoothed and LFADS-smoothed neural trajectories for 25 random trials for each target direction.

```{python}
#| label: co_neural_trajectories
#| fig-cap: 
#|   - "Gaussian-smoothed neural trajectories of 25 random trials per target direction (indicated by color)"
#|   - "LFADS-smoothed neural trajectories of 25 random trials per target direction (indicated by color)"
 
target_dirs = td_co['tgtDir'].unique()
dir_colors = plt.get_cmap('Dark2',8)
co_smoothed_trace_plot = k3d.plot(name='CO Gaussian-smoothed neural traces')
co_lfads_trace_plot = k3d.plot(name='CO LFADS-smoothed neural traces')
for dirnum,target_dir in enumerate(target_dirs):
    # plot traces
    color_val = int(255*dir_colors(dirnum)[0]) << 16 | int(255*dir_colors(dirnum)[1]) << 8 | int(255*dir_colors(dirnum)[2])
    td_co_dir = td_co.loc[np.isclose(td_co['tgtDir'],target_dir)]

    for _,trial in td_co_dir.sample(n=25).iterrows():
        co_smoothed_trace_plot+=k3d.line(trial['M1_pca'][:,0:3].astype(np.float32),shader='mesh',width=1e-3,color=color_val)
        co_lfads_trace_plot+=k3d.line(trial['lfads_pca'][:,0:3].astype(np.float32),shader='mesh',width=1e-3,color=color_val)

    co_smoothed_trace_plot+=k3d.line(
        td_co_dir['M1_pca'].mean()[:,0:3].astype(np.float32),
        shader='mesh',
        width=5e-3,
        color=color_val
    )
    co_lfads_trace_plot+=k3d.line(
        td_co_dir['lfads_pca'].mean()[:,0:3].astype(np.float32),
        shader='mesh',
        width=5e-3,
        color=color_val
    )

co_smoothed_trace_plot.display()
co_lfads_trace_plot.display()
```

LFADS neural trajectories are so much cleaner! Though there is still some trial-to-trial variability, we can actually see separation of the neural trajectories at a single trial level with the LFADS-smoothed trajectories, which we couldn't really see with the Gaussian-smoothed trajectories.

We can do the same comparison for CST as well. Though we don't have any target directions for CST, we'll color the neural traces based on horizontal hand velocity.

```{python}
#| label: cst_neural_trajectories
#| fig-cap: 
#|   - "Gaussian-smoothed neural trajectories of 10 random CST trials, colored by horizontal hand velocity"
#|   - "LFADS-smoothed neural trajectories of the same 10 random CST trials, colored by horizontal hand velocity"
 
cst_gauss_trace_plot = k3d.plot(name='CST smoothed neural traces')
cst_lfads_trace_plot = k3d.plot(name='CST LFADS neural traces')
max_abs_hand_vel = np.percentile(np.abs(np.row_stack(td_cst['hand_vel'])[:,0]),95)
# plot traces
for _,trial in td_cst.sample(n=10).iterrows():
    cst_gauss_trace_plot+=k3d.line(
        trial['M1_pca'][:,0:3].astype(np.float32),
        shader='mesh',
        width=3e-3,
        attribute=trial['hand_vel'][:,0],
        color_map=k3d.paraview_color_maps.Erdc_divHi_purpleGreen,
        color_range=[-max_abs_hand_vel,max_abs_hand_vel],
    )
    cst_lfads_trace_plot+=k3d.line(
        trial['lfads_pca'][:,0:3].astype(np.float32),
        shader='mesh',
        width=3e-3,
        attribute=trial['hand_vel'][:,0],
        color_map=k3d.paraview_color_maps.Erdc_divHi_purpleGreen,
        color_range=[-max_abs_hand_vel,max_abs_hand_vel],
    )

cst_gauss_trace_plot.display()
cst_lfads_trace_plot.display()
```

Here, both LFADS and Gaussian-smoothed neural trajectories look a bit messy, but there does appear to be a little bit more structure to the LFADS-smoothed trajectories, which are sort of arranged in a butterfly-like shape, with each lobe corresponding to either left or right hand movement.

## LFADS-smoothing improves neural decoding accuracy

...this is currently in another notebook.

# Tangling in LFADS-smoothed neural trajectories

```{python}
td_co = src.data.add_trial_time(td_co,ref_event='idx_goCueTime')
df_co = src.util.crystallize_dataframe(td_co,sig_guide=['trialtime','M1_pca','dM1_pca','lfads_pca','dlfads_pca','lfads_inputs','rel_hand_pos','hand_vel','cursor_pos','cursor_vel'])
meta_co = src.util.extract_metaframe(td_co,metacols=['trial_id','tgtDir','tgtMag'])
df_co = df_co.join(meta_co,on='trial_id')
co_measures = pd.DataFrame(
    data = {
        'Time from go cue': df_co[('trialtime',0)],
        'Target direction': df_co[('tgtDir','tgtDir')],
        'Target magnitude': df_co[('tgtMag','tgtMag')],
        'X hand position': df_co[('rel_hand_pos',0)],
        'X hand velocity': df_co[('hand_vel',0)],
        'X cursor position': df_co[('cursor_pos',0)],
        'X cursor velocity': df_co[('cursor_vel',0)],
        'LFADS input norm': np.linalg.norm(df_co['lfads_inputs'],axis=1),
        'Smoothed tangling': src.dynamics.estimate_neural_tangling(df_co,x='M1_pca',dx='dM1_pca',num_sample_points=2500),
        'LFADS tangling': src.dynamics.estimate_neural_tangling(df_co,x='lfads_pca',dx='dlfads_pca',num_sample_points=2500),
    },
    index=df_co.index,
)
co_measures
```

```{python}
td_cst = src.data.add_trial_time(td_cst,ref_event='idx_goCueTime')
df_cst = src.util.crystallize_dataframe(td_cst,sig_guide=['trialtime','M1_pca','dM1_pca','lfads_pca','dlfads_pca','lfads_inputs','rel_hand_pos','hand_vel','rel_cursor_pos','cursor_vel'])
meta_cst = src.util.extract_metaframe(td_cst,metacols=['trial_id','lambda'])
df_cst = df_cst.join(meta_cst,on='trial_id')
cst_measures = pd.DataFrame(
    data = {
        'Time from go cue': df_cst[('trialtime',0)],
        'Lambda': df_cst[('lambda','lambda')],
        'X hand position': df_cst[('rel_hand_pos',0)],
        'X hand velocity': df_cst[('hand_vel',0)],
        'X cursor position': df_cst[('rel_cursor_pos',0)],
        'X cursor velocity': df_cst[('cursor_vel',0)],
        'LFADS input norm': np.linalg.norm(df_cst['lfads_inputs'],axis=1),
        'Smoothed tangling': src.dynamics.estimate_neural_tangling(df_cst,x='M1_pca',dx='dM1_pca',num_sample_points=2500),
        'LFADS tangling': src.dynamics.estimate_neural_tangling(df_cst,x='lfads_pca',dx='dlfads_pca',num_sample_points=2500),
    },
    index=df_cst.index,
)
cst_measures
```

```{python}
# cst_measures_melt = pd.concat(
#     [
#         pd.DataFrame(
#             data = {
#                 'LFADS input norm': np.linalg.norm(df_cst['lfads_inputs'],axis=1),
#                 'X hand position': df_cst[('rel_hand_pos',0)],
#                 'X hand velocity': df_cst[('hand_vel',0)],
#                 'X cursor position': df_cst[('rel_cursor_pos',0)],
#                 'X cursor velocity': df_cst[('cursor_vel',0)],
#             },
#             index=df_cst.index,
#         ).melt(ignore_index=False,var_name='Name',value_name='Signal'),
#         pd.DataFrame(
#             data = {
#                 'Smoothed tangling': src.dynamics.rand_sample_tangling(num_samples=30,data=df_cst,x='M1_pca',dx='dM1_pca',num_sample_points=2500),
#                 'LFADS tangling': src.dynamics.rand_sample_tangling(num_samples=30,data=df_cst,x='lfads_pca',dx='dlfads_pca',num_sample_points=2500),
#             },
#         ).melt(ignore_index=False,var_name='Name',value_name='Signal')
#     ],
#     axis=0,
# )
# cst_measures_melt['Time from go cue'] = df_cst['trialtime'].squeeze().reindex(cst_measures.index)

# trial = cst_measures_melt.groupby('trial_id').get_group(313)
# g = sns.FacetGrid(
#     trial.reset_index(),
#     row='Name',
#     height=2,
#     aspect=4,
#     row_order=['Smoothed tangling','LFADS tangling','LFADS input norm','X hand position'],
#     sharey=False,
# )
# g.map(sns.lineplot,'Time from go cue','Signal')
# 
# for ax in g.axes.flatten():
#     ax.plot([0,0],ax.get_ylim(),'k--')
# 
# sns.despine(fig=g.figure,trim=True)
```

## CO single trial inspection

Here let's take a look at the single trial CO data, plotting the time course of tangling, LFADS inputs, and behavior. I'll plot the tangling of both the Gaussian smoothed neural data and the LFADS-smoothed neural data as a comparison--it's unlikely that the Gaussian-smoothed tangling will look interpretable, but hopefully the LFADS tangling will, and hopefully it'll match the timing of the LFADS inputs.

```{python}
from ipywidgets import interact
@interact(co_trial_id=list(df_co.groupby('trial_id').groups.keys()))
def plot_trials(co_trial_id):
    trial = co_measures.groupby('trial_id').get_group(co_trial_id)

    x_vars = ['Time from go cue']
    y_vars = ['Smoothed tangling','LFADS tangling','LFADS input norm','X hand position','X hand velocity']
    g=sns.PairGrid(
        trial[x_vars+y_vars],
        y_vars=y_vars,
        x_vars=x_vars,
        height=2,
        aspect=4,
    )

    g.map(sns.lineplot)

    for ax in g.axes.flatten():
        ax.plot([0,0],ax.get_ylim(),'k--')

    sns.despine(fig=g.figure,trim=True)
```

Looks like it does a pretty good job on most trials of recapitulating the intuitions from above. The timing of high tangling generally seems to be just after the go cue, and this matches the LFADS input timing also.

Just for completeness, here's the trial averaged timecourses of all of that (to be clear, this is calculating tangling on single trials and then averaging, rather than the reverse, as in Russo 2018)

```{python}
x_vars = ['Time from go cue']
y_vars = ['Smoothed tangling','LFADS tangling','LFADS input norm','X hand position']
hue_var = 'Target direction'
style_var = 'Target magnitude'
g=sns.PairGrid(
    co_measures[x_vars+y_vars+[hue_var,style_var]],
    y_vars=y_vars,
    x_vars=x_vars,
    hue=hue_var,
    height=2,
    aspect=4,
)

g.map(sns.lineplot)
g.add_legend()

for ax in g.axes.flatten():
    ax.plot([0,0],ax.get_ylim(),'k--')

sns.despine(fig=g.figure,trim=True)
```

Here, it seems like on average, the LFADS tangling is pulling something out that is there in the actual data, but a little bit messier. And it's nice that it matches up with the LFADS inputs, which is a good proof of concept that the LFADS inputs are reasonable.

## CST single trial inspection

Now time to look at CST single trials in the same way.

```{python}
@interact(cst_trial_id=list(cst_measures.groupby('trial_id').groups.keys()))
def plot_trials(cst_trial_id):
    trial = cst_measures.groupby('trial_id').get_group(cst_trial_id)
    x_vars = ['Time from go cue']
    y_vars = ['LFADS tangling','LFADS input norm','X hand position','X hand velocity']
    g=sns.PairGrid(
        trial[x_vars+y_vars],
        y_vars=y_vars,
        x_vars=x_vars,
        height=2,
        aspect=4,
    )

    g.map(sns.lineplot)

    for ax in g.axes.flatten():
        ax.plot([0,0],ax.get_ylim(),'k--')

    sns.despine(fig=g.figure,trim=True)
```

Seems like there's something useful in there. First off, tangling and LFADS inputs seem to roughly match up and also seem to be somewhat intermittent. High tangling also sometimes seems to occur just before large movements, and often during what look like holding periods. More investigation on that later...

For completeness again, let's look at the trial averaged values of CST. Here, I don't expect to find much structure, since each trial is structurally different, but possibly there's some overall trend we can see.

```{python}
x_vars = ['Time from go cue']
y_vars = ['LFADS tangling','LFADS input norm','X hand position']
hue_var = 'Lambda'
g=sns.PairGrid(
    cst_measures[x_vars+y_vars+[hue_var]],
    y_vars=y_vars,
    x_vars=x_vars,
    hue=hue_var,
    height=2,
    aspect=4,
)

g.map(sns.lineplot)
g.add_legend()

for ax in g.axes.flatten():
    ax.plot([0,0],ax.get_ylim(),'k--')

sns.despine(fig=g.figure,trim=True)
```

As expected, not a whole lot there, but there is kind of a weird upward trend as the trial goes forward. Perhaps this indicates more input-driven behavior later in the trial? That would make sense, since later in the trial would correspond to larger movements generally.

It's worth comparing neural tangling between CO and CST. Because CST is highly input driven, we might expect that tangling would be higher in CST than in CO.

```{python}
x_vars = ['Time from go cue','LFADS tangling','LFADS input norm','X hand position','X hand velocity','X cursor position','X cursor velocity']
cocst_tangling = pd.concat(
    [co_measures[x_vars],cst_measures[x_vars]],
    axis=0,
    keys=['CO','CST'],
)
cocst_tangling.index.rename('Task',level=0,inplace=True)
cocst_tangling
sns.displot(
    data=cocst_tangling,
    x='LFADS tangling',
    hue='Task',
    kind='kde',
)
```

Surprisingly, this seems to not really be the case. I'm not exactly sure why that is, but it's possible that we just can't really compare the two tasks, since they necessitate slightly different tangling calculations.

## Quantification of tangling and LFADS inputs

It seems like tangling and high LFADS input precede large movements, as we might expect from a signal indicating the onset of some intermittent movement or adjustment. Let's try to uncover this relationship (if it's there).

First, let's just verify that tangling and LFADS input norm are highly correlated to start with.

```{python}
# sns.jointplot(
#     data=cocst_tangling,
#     x='LFADS tangling',
#     y='LFADS input norm',
#     col='Task',
#     kind='reg',
# )
g = sns.FacetGrid(
    data=cocst_tangling.reset_index(),
    col='Task',
    height=6,
    row_order=['CO','CST'],
)
g.map(sns.regplot,'LFADS tangling','LFADS input norm')
sns.despine(fig=g.figure,trim=True)
```

Hmm... not super convincing on the CO plot, but there does seem to be a bit of a bimodal distribution there. Let's try out a different plot to see if that's the case.

```{python}
g = sns.FacetGrid(
    data=cocst_tangling.reset_index(),
    col='Task',
    height=6,
    row_order=['CO','CST'],
)
g.map(sns.kdeplot,'LFADS tangling','LFADS input norm')
sns.despine(fig=g.figure,trim=True)
```

I think there probably is some sort of bimodality in there with high LFADS input but low tangling that's throwing this whole thing off. Without that top lobe, tangling would probably correlate okay with LFADS input. What that top lobe of the distributional plot is, I'm not sure. But it's a problem for another time.

## Cross-correlation between tangling and hand speed

Let's move onto the cross-correlograms between tangling and horizontal hand speed! For this, we'll cross-correlate tangling and hand speed trial-by-trial and then average the cross-correlograms together.

Mechanistically, this involves grouping by `trial_id`, computing the cross-correlogram for each group (which results in its own DataFrame with index `(trial_id, Lag bin)`), and then concatenating all of those together. We can then plot the result using Seaborn pretty easily.

```{python}
from scipy.signal import correlate, correlation_lags

tangling_vel_corr = (
    cocst_tangling.groupby(['Task','trial_id'])
    .apply(
        lambda s: pd.Series({
            'Cross-correlation': correlate(s['LFADS tangling'],(s['X hand velocity'])),
            'Lag bin': correlation_lags(len(s['LFADS tangling']),len(s['X hand velocity'])),
            'Lag time (s)': correlation_lags(len(s['LFADS tangling']),len(s['X hand velocity']))*analysis_params['bin_size'],
        })
    )
    .explode(column=['Cross-correlation','Lag bin','Lag time (s)'])
    .set_index('Lag bin',append=True)
)

tang_vel_ax = sns.lineplot(
    data=tangling_vel_corr,
    x='Lag time (s)',
    y='Cross-correlation',
    hue='Task',
)

tang_vel_ax.plot(
    [0,0],
    tang_vel_ax.get_ylim(),
    'k-',
)
tang_vel_ax.plot(
    tang_vel_ax.get_xlim(),
    [0,0],
    'k-',
)
tang_vel_ax.set_xlim([-2,2])

sns.despine(ax=tang_vel_ax,trim=True)
```

Well... I accidentally cross-correlated the tangling with the hand velocity instead of hand speed, and I found something kind of interesting. It seems as though the tangling is negatively correlated with previous hand velocities and positively correlated with future hand velocities (or vice versa--I haven't figured out what positive lag means here yet). I suppose this means that at points of high tangling there's a sharp autocorrelation in the hand velocity signal? Because normally I would expect hand velocity autocorrelation to be quite wide, which would mean that this kind of result shouldn't be happening. But if tangling indicates some sort of change point in hand velocity (i.e. it happens right as monkeys change direction), then maybe this is what I would expect. But only if it indicated monkeys changing direction in a signed way, i.e. acceleration specifically to the right (or left--again, haven't figured out the signs here yet).

Anyway, here's the actual thing I originally wanted to plot:

```{python}
tangling_speed_corr = (
    cocst_tangling.groupby(['Task','trial_id'])
    .apply(
        lambda s: pd.Series({
            'Cross-correlation': correlate(s['LFADS tangling'],np.abs(s['X hand velocity'])),
            'Lag bin': correlation_lags(len(s['LFADS tangling']),len(s['X hand velocity'])),
            'Lag time (s)': correlation_lags(len(s['LFADS tangling']),len(s['X hand velocity']))*analysis_params['bin_size'],
        })
    )
    .explode(column=['Cross-correlation','Lag bin','Lag time (s)'])
    .set_index('Lag bin',append=True)
)

tang_speed_ax = sns.lineplot(
    data=tangling_speed_corr,
    x='Lag time (s)',
    y='Cross-correlation',
    hue='Task',
)
tang_speed_ax.plot(
    [0,0],
    tang_speed_ax.get_ylim(),
    'k-',
)
tang_speed_ax.set_xlim([-1,1])

sns.despine(ax=tang_speed_ax,trim=True)
```

This seems much more reasonable--a lag somewhere near zero, but probably to one side or the other (haven't looked at the actual location of the max). I would expect the tangling to lead the hand speed somehow.

I guess this means that maybe I should do a cross-correlation with hand acceleration also? Something for the future.

One thing that comes to mind is the fact that cross-correlation has some boundary effects thanks to zero padding on the edges--so if we auto-correlated two constant functions, we would get something with a peak, even though the cross-correlation should be flat. I can try to fix this by implementing a version of cross-correlation that normalizes the value at each lag by the number of points used to calculate it. I can also normalize by the RMS of each signal so that the autocorrelation of each signal would be 1--this should give something more like a Pearson's correlation coefficient.

```{python}
tangling_speed_corr = (
    cocst_tangling.groupby(['Task','trial_id'])
    .apply(
        lambda s: pd.Series({
            'Cross-correlation': src.analysis.normalized_cross_correlation(s['LFADS tangling'],np.abs(s['X hand velocity'])),
            'Lag bin': correlation_lags(len(s['LFADS tangling']),len(s['X hand velocity'])),
            'Lag time (s)': correlation_lags(len(s['LFADS tangling']),len(s['X hand velocity']))*analysis_params['bin_size'],
        })
    )
    .explode(column=['Cross-correlation','Lag bin','Lag time (s)'])
    .set_index('Lag bin',append=True)
)

tang_speed_ax = sns.lineplot(
    data=tangling_speed_corr,
    x='Lag time (s)',
    y='Cross-correlation',
    hue='Task',
)
tang_speed_ax.plot(
    [0,0],
    tang_speed_ax.get_ylim(),
    'k-',
)
tang_speed_ax.set_xlim([-1,1])

sns.despine(ax=tang_speed_ax,trim=True)
```

Much flatter... And there's a weird upward trend at negative lags for the CO cross-correlation. I'm not sure this makes sense. Maybe there's an issue with the trial structure interfering with the cross-correlation? perhaps it would be better if I concatenated a bunch of trials together. But then the issue is that there will be jumps in the intertrial intervals, which may cause some issues...

Let's go back to the velocity correlation... I wonder how much this tangling stuff relates to the cursor velocity. I would expect the monkey to switch tracks most when the cursor velocity is high, and move to bring the cursor velocity down.

```{python}
from scipy.signal import correlate, correlation_lags

tangling_vel_corr = (
    cocst_tangling.groupby(['Task','trial_id'])
    .apply(
        lambda s: pd.Series({
            'Cross-correlation': src.analysis.normalized_cross_correlation(s['LFADS tangling'],(s['X cursor velocity'])),
            'Lag bin': correlation_lags(len(s['LFADS tangling']),len(s['X hand velocity'])),
            'Lag time (s)': correlation_lags(len(s['LFADS tangling']),len(s['X hand velocity']))*analysis_params['bin_size'],
        })
    )
    .explode(column=['Cross-correlation','Lag bin','Lag time (s)'])
    .set_index('Lag bin',append=True)
)

tang_vel_ax = sns.lineplot(
    data=tangling_vel_corr,
    x='Lag time (s)',
    y='Cross-correlation',
    hue='Task',
)

tang_vel_ax.plot(
    [0,0],
    tang_vel_ax.get_ylim(),
    'k-',
)
tang_vel_ax.plot(
    tang_vel_ax.get_xlim(),
    [0,0],
    'k-',
)
tang_vel_ax.set_xlim([-2,2])
tang_vel_ax.set_ylim([-.2,.2])

sns.despine(ax=tang_vel_ax,trim=True)
```

